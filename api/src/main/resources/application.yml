spring:
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3.1:8b
    vectorstore:
      qdrant:
        host: localhost
        port: 6334
        collection-name: atsify
        initialize-schema: true
  mail:
    host: localhost
    port: 1025
    username: ${TEST_MAIL_USERNAME}
    password: ${TEST_MAIL_PASSWORD}
    properties:
      mail:
        smtp:
          trust: "*"
        auth: true
        starttls:
          enabled: true
        connectiontimeout: 5000
        timeout: 3000
        writetimeout: 5000
  docker:
    compose:
      stop:
        command: down
      file: api/compose.yml
management:
  endpoints:
    web:
      exposure:
        include: "health,metrics,prometheus"
  tracing:
    sampling:
      probability: 0.1
  metrics:
    tags:
      application: ${spring.application.name:api}
opentelemetry:
  exporter:
    otlp:
      endpoint: http://localhost:4317
logging:
  level:
    org:
      springframework:
        ai:
          chat:
            client:
              advisor: DEBUG